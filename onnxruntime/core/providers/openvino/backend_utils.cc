// Copyright (C) Intel Corporation
// Licensed under the MIT License

#include <algorithm>
#include <sstream>
#include <fstream>
#include <utility>

#include <filesystem>
#include <stdexcept>

#include "openvino/pass/convert_fp32_to_fp16.hpp"
#include "openvino/pass/constant_folding.hpp"
#include "openvino/runtime/intel_npu/level_zero/level_zero.hpp"
#include "core/providers/shared_library/provider_api.h"
#include "core/providers/openvino/backend_utils.h"
#include "core/providers/openvino/ov_interface.h"

#ifdef _WIN32
#include "Windows.h"
#else
#include <fcntl.h>       // For open
#include <sys/mman.h>    // For mmap, munmap
#include <sys/stat.h>    // For fstat
#include <unistd.h>      // For close
#endif

using Exception = ov::Exception;

namespace onnxruntime {
namespace openvino_ep {

#ifdef _WIN32
SharedContext::SharedWeights::MappedWeights::MappedWeights(std::filesystem::path filename) {
  file_ = CreateFile(filename.string().data(),
                     GENERIC_READ,
                     FILE_SHARE_READ,
                     0,
                     OPEN_EXISTING,
                     FILE_ATTRIBUTE_NORMAL,
                     0);
  ORT_ENFORCE(file_ != nullptr, "Unable to open weight file at ", filename.string());

  mapping_ = CreateFileMapping(file_, 0, PAGE_READONLY, 0, 0, 0);
  ORT_ENFORCE(mapping_ != nullptr, "Unable to create mapping of weight file at ", filename.string());

  const char* raw_data = static_cast<const char*>(MapViewOfFile(mapping_, FILE_MAP_READ, 0, 0, 0));
  ORT_ENFORCE(raw_data != nullptr, "Unable to map weight file at ", filename.string());

  weight_data = std::string_view(raw_data, std::filesystem::file_size(filename));
}

SharedContext::SharedWeights::MappedWeights::~MappedWeights() {
  if (!weight_data.empty()) {
    UnmapViewOfFile(weight_data.data());
  }
  if (mapping_ != nullptr) {
    CloseHandle(mapping_);
    mapping_ = nullptr;
  }
  if (file_ != nullptr) {
    CloseHandle(file_);
    file_ = nullptr;
  }
}
#else
SharedContext::SharedWeights::MappedWeights::MappedWeights(std::filesystem::path filename)
    : file_(nullptr), mapping_(nullptr) {
    // Open the file
    int fd = open(filename.c_str(), O_RDONLY);
    if (fd == -1) {
        ORT_THROW("Unable to open weight file at " + filename.string());
    }

    // Get file size
    struct stat file_stat;
    if (fstat(fd, &file_stat) == -1) {
        close(fd);
        ORT_THROW("Unable to get file size for " + filename.string());
    }
    size_t file_size = file_stat.st_size;

    // Map the file into memory
    void* raw_data = mmap(nullptr, file_size, PROT_READ, MAP_PRIVATE, fd, 0);
    if (raw_data == MAP_FAILED) {
        close(fd);
        ORT_THROW("Unable to map weight file at " + filename.string());
    }

    // Set class members
    file_ = reinterpret_cast<void*>(fd);       // Store file descriptor
    mapping_ = raw_data;                       // Store mapping address
    weight_data = std::string_view(static_cast<const char*>(raw_data), file_size);

    // Close the file descriptor, as mmap does not need it open
    close(fd);
}

SharedContext::SharedWeights::MappedWeights::~MappedWeights() {
    // Unmap memory if it was mapped
    if (mapping_ != nullptr) {
        munmap(mapping_, weight_data.size());
        mapping_ = nullptr;
    }

    // Clear the file descriptor, though it was already closed after mmap
    file_ = nullptr;
}
#endif

std::ostream& operator<<(std::ostream& stream, const SharedContext::SharedWeights::Metadata::Map& metadata) {
  try {
    stream << metadata.size();

    // Write each key-value pair
    // Put elements in separate lines to facilitate reading
    for (const auto& [key, value] : metadata) {
      stream << std::endl
             << key.name;
      stream << std::endl
             << value.location;
      stream << std::endl
             << value.data_offset;
      stream << std::endl
             << value.size;
      stream << std::endl
             << value.dimensions.size();
      for (const auto& dim : value.dimensions) {
        stream << std::endl
               << dim;
      }
      stream << std::endl
             << value.element_type;
    }
  } catch (const Exception& e) {
    ORT_THROW("Error: Failed to write map data.", e.what());
  } catch (...) {
    ORT_THROW("Error: Failed to write map data.");
  }

  ORT_ENFORCE(stream.good(), "Error: Failed to write map data.");
  return stream;
}

std::istream& operator>>(std::istream& stream, SharedContext::SharedWeights::Metadata::Map& metadata) {
  size_t map_size{0};
  try {
    stream >> map_size;

    while (!stream.eof()) {
      SharedContext::SharedWeights::Metadata::Key key;
      SharedContext::SharedWeights::Metadata::Value value;
      stream >> key.name;
      stream >> value.location;
      stream >> value.data_offset;
      stream >> value.size;
      size_t num_dimensions;
      stream >> num_dimensions;
      value.dimensions.resize(num_dimensions);
      for (auto& dim : value.dimensions) {
        stream >> dim;
      }
      stream >> value.element_type;
      metadata.emplace(key, value);
    }
  } catch (const Exception& e) {
    ORT_THROW("Error: Failed to read map data.", e.what());
  } catch (...) {
    ORT_THROW("Error: Failed to read map data.");
  }

  ORT_ENFORCE(metadata.size() == map_size, "Error: Inconsistent map data.");

  return stream;
}

namespace backend_utils {

bool IsDebugEnabled() {
  const std::string env_name = onnxruntime::GetEnvironmentVar("ORT_OPENVINO_ENABLE_DEBUG");
  if (!env_name.empty()) {
    return true;
  }
  return false;
}

bool IsCILogEnabled() {
  const std::string env_name = onnxruntime::GetEnvironmentVar("ORT_OPENVINO_ENABLE_CI_LOG");
  if (!env_name.empty()) {
    return true;
  }
  return false;
}

std::shared_ptr<const OVNetwork>
CreateOVModel(const std::string model,
              const SessionContext& session_context,
              const SubGraphContext& subgraph_context,
              std::map<std::string, std::shared_ptr<ov::Node>>& const_outputs_map) {
  if (IsCILogEnabled()) {
    std::cout << "CreateNgraphFunc" << std::endl;
  }
  try {
    auto ov_model = OVCore::ReadModel(model, session_context.onnx_model_path_name.string());

    if(!session_context.shape.empty()) {
      LOGS_DEFAULT(INFO) << log_tag << "Reshaping the ov tensor to specified shape";
      ov_model->reshape(session_context.shape);
    }

    // Check for Constant Folding
    if ((session_context.device_type != "NPU") && !subgraph_context.is_wholly_supported_graph) {
      ov::pass::ConstantFolding pass_const_obj;
      pass_const_obj.run_on_model(ov_model);
      auto& results = const_cast<ov::ResultVector&>(ov_model.get()->get_results());
      size_t index = results.size() - 1;

      for (auto it = results.rbegin(); it != results.rend(); ++it) {
        if (auto const_node =
                std::dynamic_pointer_cast<ov::op::v0::Constant>((*it)->input_value(0).get_node_shared_ptr())) {
          const_outputs_map[(*it)->get_friendly_name()] = const_node;
          results.erase(results.begin() + index);
        }
        --index;
      }
    }
#ifndef NDEBUG
    if (IsDebugEnabled()) {
      std::string name = ov_model->get_friendly_name();
      ov::pass::Serialize serializer(name + ".xml", name + ".bin");
      serializer.run_on_model(ov_model);
    }
#endif
    return ov_model;
  } catch (std::string const& msg) {
    ORT_THROW(msg);
  }
}

Ort::UnownedValue
GetOutputTensor(Ort::KernelContext& context, size_t batch_size,
                OVInferRequestPtr infer_request,
                std::string output_name,
                const SubGraphContext::string_index_map_t& output_names) {
  auto graph_output_blob = infer_request->GetTensor(output_name);

  auto graph_output_dims = graph_output_blob->get_shape();

  if (batch_size > 1) {
    // Add the batch size as dim 0.
    graph_output_dims.insert(graph_output_dims.begin(), batch_size);
  }
  size_t num_dims = graph_output_dims.size();
  std::unique_ptr<int64_t[]> output_shape(new int64_t[num_dims]);
  for (size_t j = 0; j < num_dims; j++) {
    output_shape[j] = static_cast<int64_t>(graph_output_dims[j]);
  }
  auto it = output_names.find(output_name);
  if (it == output_names.end()) {
    ORT_THROW(log_tag + "Output names mismatch between OpenVINO and ONNX");
  }
  int index = it->second;
  return context.GetOutput(index, output_shape.get(), num_dims);
}

Ort::UnownedValue
GetOutputTensor(Ort::KernelContext& context,
                std::string output_name,
                const SubGraphContext::string_index_map_t& output_names,
                std::shared_ptr<ov::Node> node) {
  // Find position of '/' in the output_name
  int pos = output_name.find("/");
  // Copy the substring from start to pos
  output_name = output_name.substr(0, pos);

  auto it = output_names.find(output_name);
  if (it == output_names.end()) {
    ORT_THROW(log_tag + "Output names mismatch between OpenVINO and ONNX");
  }
  int index = it->second;
  auto shape = node->get_shape();

  size_t num_dims = shape.size();
  std::unique_ptr<int64_t[]> output_shape(new int64_t[num_dims]);
  for (size_t j = 0; j < num_dims; j++) {
    output_shape[j] = static_cast<int64_t>(shape[j]);
  }
  return context.GetOutput(index, output_shape.get(), num_dims);
}

int GetFirstAvailableDevice(SessionContext& session_context) {
  int i = 0;
  // Get the first available VAD-M device and set the device to busy
  while (i < 8) {
    bool device = session_context.deviceAvailableList[i];
    if (device) {
      session_context.deviceAvailableList[i] = false;
      break;
    }
    i++;
  }
  // If all of the devices are busy, assign the first device and
  // make all remaining devices free
  if (i == 8) {
    i = 0;
    session_context.deviceAvailableList[i] = false;
    for (int j = 1; j < 8; j++) {
      session_context.deviceAvailableList[j] = true;
    }
  }
  return i;
}

void FillOutputsWithConstantData(std::shared_ptr<ov::Node> node, Ort::UnownedValue& out_tensor) {
  switch (node->get_element_type()) {
    case ov::element::Type_t::f32: {
      FillOutputHelper<float>(out_tensor, node);
      break;
    }
    case ov::element::Type_t::boolean: {
      FillOutputHelper<char>(out_tensor, node);
      break;
    }
    case ov::element::Type_t::i32: {
      FillOutputHelper<int32_t>(out_tensor, node);
      break;
    }
    case ov::element::Type_t::i64: {
      FillOutputHelper<int64_t>(out_tensor, node);
      break;
    }
    case ov::element::Type_t::f16: {
      FillOutputHelper<float>(out_tensor, node);
      break;
    }
    default:
      ORT_THROW(log_tag + "Unsupported output data type");
  }
}

#if defined(_MSC_VER)
#pragma warning(disable : 4127)
#endif

template <typename T>
void FillOutputHelper(Ort::UnownedValue& out_tensor, std::shared_ptr<ov::Node> node) {
  auto const_node = std::dynamic_pointer_cast<ov::op::v0::Constant>(node);
  auto res = const_node->cast_vector<T>();
  T* tensor_data = out_tensor.GetTensorMutableData<T>();
  std::copy(res.begin(), res.end(), tensor_data);
}

#if defined(_MSC_VER)
#pragma warning(default : 4127)
#endif

void FillInputBlob(OVTensorPtr inputBlob, size_t batch_slice_idx,
                   std::string input_name, Ort::KernelContext& context,
                   const SubGraphContext& subgraph_context) {
  size_t input_data_size = inputBlob->get_byte_size();
  auto input_data = inputBlob->data();
  auto tensor = context.GetInput(subgraph_context.input_names.at(input_name));
  auto mem_info = tensor.GetTensorMemoryInfo();
  if (mem_info.GetAllocatorName() == OpenVINO_GPU) {
    ORT_THROW(log_tag + "IO Buffering is not enabled, Please enable Input on CPU");
  }
  // Copy input data into OpenVINO's input buffer
  const char* tensor_data = tensor.GetTensorData<char>();
  const char* batch_memory_offset = tensor_data + input_data_size * batch_slice_idx;
  std::memcpy(input_data, batch_memory_offset, input_data_size);
}

void FillOutputBlob(OVTensorPtr outputBlob, Ort::UnownedValue& output_tensor,
                    size_t batch_slice_idx) {
  auto output_data = outputBlob->data();
  size_t output_data_size = outputBlob->get_byte_size();
  char* tensor_data = output_tensor.GetTensorMutableData<char>();
  char* batch_memory_offset = tensor_data + output_data_size * batch_slice_idx;
  std::memcpy(batch_memory_offset, output_data, output_data_size);
}

void printPerformanceCounts(const std::vector<OVProfilingInfo>& performanceMap,
                            std::ostream& stream, std::string deviceName) {
  int64_t totalTime = 0;
  // Print performance counts
  stream << std::endl
         << "performance counts:" << std::endl
         << std::endl;

  for (const auto& it : performanceMap) {
    std::string toPrint(it.node_name);
    const int maxLayerName = 30;

    if (it.node_name.length() >= maxLayerName) {
      toPrint = it.node_name.substr(0, maxLayerName - 4);
      toPrint += "...";
    }
    stream << std::setw(maxLayerName) << std::left << toPrint;
    switch (it.status) {
      case OVProfilingInfo::Status::EXECUTED:
        stream << std::setw(15) << std::left << "EXECUTED";
        break;
      case OVProfilingInfo::Status::NOT_RUN:
        stream << std::setw(15) << std::left << "NOT_RUN";
        break;
      case OVProfilingInfo::Status::OPTIMIZED_OUT:
        stream << std::setw(15) << std::left << "OPTIMIZED_OUT";
        break;
    }
    stream << std::setw(30) << std::left << "layerType: " + std::string(it.node_type) + " ";
    stream << std::setw(20) << std::left << "realTime: " + std::to_string(it.real_time.count());
    stream << std::setw(20) << std::left << "cpu: " + std::to_string(it.cpu_time.count());
    stream << " execType: " << it.exec_type << std::endl;
    if (it.real_time.count() > 0) {
      totalTime += it.real_time.count();
    }
  }
  stream << std::setw(20) << "Total time: " + std::to_string(totalTime) << " microseconds" << std::endl;
  std::cout << std::endl;
  std::cout << "Full device name: " << deviceName << std::endl;
  std::cout << std::endl;
}

void printPerformanceCounts(OVInferRequestPtr request, std::ostream& stream, std::string deviceName) {
  auto performanceMap = request->GetNewObj().get_profiling_info();
  printPerformanceCounts(performanceMap, stream, std::move(deviceName));
}

ov::element::Type GetOpenVINOElementType(ONNX_NAMESPACE::TensorProto_DataType dt) {
  static std::unordered_map<ONNX_NAMESPACE::TensorProto_DataType, ov::element::Type> map{
      {ONNX_NAMESPACE::TensorProto_DataType_FLOAT, ov::element::f32},
      {ONNX_NAMESPACE::TensorProto_DataType_UINT8, ov::element::u8},
      {ONNX_NAMESPACE::TensorProto_DataType_INT8, ov::element::i8},
      {ONNX_NAMESPACE::TensorProto_DataType_UINT16, ov::element::u16},
      {ONNX_NAMESPACE::TensorProto_DataType_INT16, ov::element::i16},
      {ONNX_NAMESPACE::TensorProto_DataType_INT32, ov::element::i32},
      {ONNX_NAMESPACE::TensorProto_DataType_INT64, ov::element::i64},
      {ONNX_NAMESPACE::TensorProto_DataType_STRING, ov::element::string},
      {ONNX_NAMESPACE::TensorProto_DataType_BOOL, ov::element::boolean},
      {ONNX_NAMESPACE::TensorProto_DataType_FLOAT16, ov::element::f16},
      {ONNX_NAMESPACE::TensorProto_DataType_DOUBLE, ov::element::f64},
      {ONNX_NAMESPACE::TensorProto_DataType_UINT32, ov::element::u32},
      {ONNX_NAMESPACE::TensorProto_DataType_UINT64, ov::element::u64},
      //{ONNX_NAMESPACE::TensorProto_DataType_COMPLEX64, ov::element::undefined},
      //{ONNX_NAMESPACE::TensorProto_DataType_COMPLEX128, ov::element::undefined},
      {ONNX_NAMESPACE::TensorProto_DataType_BFLOAT16, ov::element::bf16},
      //{ONNX_NAMESPACE::TensorProto_DataType_FLOAT8E4M3FN, ov::element::undefined},
      //{ONNX_NAMESPACE::TensorProto_DataType_FLOAT8E4M3FNUZ, ov::element::undefined},
      {ONNX_NAMESPACE::TensorProto_DataType_FLOAT8E5M2, ov::element::f8e5m2},
      //{ONNX_NAMESPACE::TensorProto_DataType_FLOAT8E5M2FNUZ, ov::element::undefined},
      {ONNX_NAMESPACE::TensorProto_DataType_UINT4, ov::element::u4},
      {ONNX_NAMESPACE::TensorProto_DataType_INT4, ov::element::i4},
  };

  if (auto result = map.find(dt); result != map.end()) {
    return result->second;
  } else {
    throw std::runtime_error("Unsupported ONNX data type: " + std::to_string(dt));
  }
}

// Function to handle tensor creation from external data
void CreateOVTensors(const std::string& device_name,
                     SharedContext::SharedWeights::Metadata::Map& metadata_map,
                     std::string_view weights) {
  for (auto& [key, value] : metadata_map) {
    if (value.tensor) continue;

    // Get tensor data
    const auto* tensor_data = weights.data() + value.data_offset;

    // Get element data type
    auto onnx_element_type = (ONNX_NAMESPACE::TensorProto_DataType)value.element_type;

    ov::element::Type ov_elementType = GetOpenVINOElementType(onnx_element_type);  // Map to OpenVINO data type

    // Create OpenVINO Tensor
    if (device_name == "NPU") {
      // Use remote tensors
      auto npu_context = OVCore::Get().get_default_context("NPU").as<ov::intel_npu::level_zero::ZeroContext>();
      auto&& remote_tensor = npu_context.create_l0_host_tensor(ov_elementType, value.dimensions, ov::intel_npu::TensorType::INPUT);

      // Copy data to remote tensor
      std::memcpy(remote_tensor.get(), (void*)tensor_data, value.size);
      value.tensor = std::make_shared<ov::Tensor>(remote_tensor);
    } else {
      // Use vanilla tensors
      value.tensor = std::make_shared<ov::Tensor>(ov_elementType, value.dimensions, (void*)tensor_data);
    }
    ORT_ENFORCE(value.tensor->get_byte_size() == value.size, "Unexpected tensor size mismatch");
  }
}

}  // namespace backend_utils
}  // namespace openvino_ep
}  // namespace onnxruntime
